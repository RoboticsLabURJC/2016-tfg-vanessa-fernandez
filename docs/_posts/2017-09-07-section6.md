---
layout: default
---
# Autopark Practice

* **Solution + Referee**

[![Autopark solution + Referee (JdeRobot Academy)](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/autopark.png)](https://www.youtube.com/watch?v=2SYEb3DyWEE)


* **First solution**

[![Autopark solution + Referee (JdeRobot Academy)](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/autopark.png)](https://www.youtube.com/watch?v=2SYEb3DyWEE)


* **Testing the python dubins 0.9.2 package**

![GUI](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/gui_autopark.png)


* **OMPLapp thirs step**

[![Ompl: Examples of planning with different types of cars](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/ompl3.png)](https://www.youtube.com/watch?v=xse7LClDyy8)


* **OMPLapp second step**

[![OMPL.app](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/ompl.png)](https://www.youtube.com/watch?v=heUp3urw4a8)


* **European cars**

![European cars](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/european_autopark.png)


* **OMPLapp first step**

We've tested the OMPLapp. 

![OMPLapp](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/ompl_app.png)


* **OMPLapp**

We've installed the OMPLapp. OMPL is a library for non-olonomic movement planning. The installation steps are in the following [link](http://ompl.kavrakilab.org/installation.html).

You may have problems installing OMPL with pip, because OMPL is for Python2 (pip2). The omplapp-1.2.1-Source/py-bindings/generate_bindings.py file have an error. The error was fixed in [1](https://bitbucket.org/ompl/ompl/commits/cc3d0f4).

To launch OMPL.app, execute the ompl_app.py python script, which is found in the omplapp-1.2.1-Source/gui directory. When the GUI is loaded, a window will be presented as in the following image: 

![OMPLapp](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/ompl1.png)


* **Autopark: first step with referee**

We've added a first version of referee in autopark's practice. Also, we have marked the robot's way with points.

[![Autopark: referee (JdeRobot)](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/autopark.png)](https://www.youtube.com/watch?v=KA4oj6YfAyw)


* **Autopark (car with movement)**

[![Autopark: movement's car](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/autopark.png)](https://www.youtube.com/watch?v=cED3ypdGgys)


* **Autopark with teleoperate**

[![Autopark: teleoperate](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/autopark.png)](https://www.youtube.com/watch?v=I3EAbbyxMQc)


* **GUI with 3 Lasers in a car (Autopark)**

I've maked the gui of autopark's practice. In this case, the car has a 3 lasers. Each laser have a different color in the GUI.

![GUI](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/laser_autopark.png)


* **3 Lasers in a car + kobukiViewer**

I've modified the laser's plugin to have 3 lasers in the car. To test its operation we put the taxi in Gazebo, and then we run kobukiViewer. The kobukiViewer tool has been modified to test the taxlLaser's plugin.

![Lasers](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/laser_kobuki.png)


* **yellowTaxi with 3 lasers + kobukiViewer**

I've made a new model named taxiLaser. For this I have taken as an example the model yellowTaxi. And I've teleoperated this taxi with kobukiViewer:

[![Lasers' car](https://roboticslaburjc.github.io/2016-tfg-vanessa-fernandez/images/laser_kobuki.png)](https://www.youtube.com/watch?v=zEDIyf4lhik)







